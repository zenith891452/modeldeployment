# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GoPFcYDKQuqbGtBt4s2f2gN-NQquWJUl
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
import pickle

class HotelModelPipeline:
    def __init__(self, file_path):
        self.file_path = file_path
        self.df = None
        self.model = None
        self.label_encoders = {}

    def load_data(self):
        """Memuat dataset dari file CSV"""
        self.df = pd.read_csv(self.file_path)

    def handle_missing_values(self):
        """Menangani missing values pada kolom numerik dan kategorikal"""
        for col in self.df.columns:
            if self.df[col].dtype in ['int64', 'float64']:
                self.df[col].fillna(self.df[col].median(), inplace=True)  # Kolom numerik diisi median
            else:
                self.df[col].fillna(self.df[col].mode()[0], inplace=True)  # Kolom kategorikal diisi modus

    def encode_labels(self):
        """Melakukan label encoding pada fitur kategorikal"""
        for col in self.df.select_dtypes(include='object').columns:
            self.df[col] = self.df[col].astype('category')

        for col in self.df.select_dtypes(include='category').columns:
            le = LabelEncoder()
            self.df[col] = le.fit_transform(self.df[col])
            self.label_encoders[col] = le

    def split_data(self):
        """Membagi data menjadi fitur dan target serta train-test split"""
        X = self.df.drop(columns='booking_status')
        y = self.df['booking_status']
        return train_test_split(X, y, test_size=0.2, random_state=42)

    def tune_hyperparameters(self, X_train, X_test, y_train, y_test):
        """Mencari hyperparameters terbaik untuk Random Forest dan XGBoost"""

        # Parameter grid untuk Random Forest
        rf_param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5],
            'random_state': [42]
        }

        # Parameter grid untuk XGBoost
        xgb_param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1],
            'subsample': [0.8, 1.0],
            'colsample_bytree': [0.8, 1.0],
            'random_state': [42]
        }

        # GridSearchCV untuk Random Forest
        rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(),
                                      param_grid=rf_param_grid,
                                      cv=5, n_jobs=-1, verbose=2)
        rf_grid_search.fit(X_train, y_train)

        # GridSearchCV untuk XGBoost
        xgb_grid_search = GridSearchCV(estimator=XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
                                       param_grid=xgb_param_grid,
                                       cv=5, n_jobs=-1, verbose=2)
        xgb_grid_search.fit(X_train, y_train)

        # Pilih model terbaik berdasarkan akurasi
        rf_best_model = rf_grid_search.best_estimator_
        xgb_best_model = xgb_grid_search.best_estimator_

        # Evaluasi model terbaik
        rf_preds = rf_best_model.predict(X_test)
        xgb_preds = xgb_best_model.predict(X_test)

        rf_acc = accuracy_score(y_test, rf_preds)
        xgb_acc = accuracy_score(y_test, xgb_preds)

        # Cetak hasil
        print(f"Best Random Forest Parameters: {rf_grid_search.best_params_}")
        print(f"Best XGBoost Parameters: {xgb_grid_search.best_params_}")
        print(f"Random Forest Accuracy: {rf_acc}")
        print(f"XGBoost Accuracy: {xgb_acc}")

        # Simpan model terbaik (XGBoost berdasarkan soal)
        self.model = xgb_best_model if xgb_acc >= rf_acc else rf_best_model
        print(f"Best model selected: {'XGBoost' if xgb_acc >= rf_acc else 'Random Forest'}")

    def save_model(self, model_path='best_model.pkl', encoder_path='label_encoders.pkl'):
        """Menyimpan model dan encoder ke file pickle"""
        with open(model_path, 'wb') as f:
            pickle.dump(self.model, f)
        with open(encoder_path, 'wb') as f:
            pickle.dump(self.label_encoders, f)

    def run(self):
        """Menjalankan seluruh pipeline: load data, preprocessing, train model, dan save model"""
        self.load_data()
        self.handle_missing_values()
        self.encode_labels()
        X_train, X_test, y_train, y_test = self.split_data()
        self.tune_hyperparameters(X_train, X_test, y_train, y_test)
        self.save_model()

# Pemanggilan dan penggunaan class
if __name__ == "__main__":
    trainer = HotelModelPipeline(file_path='Dataset_B_hotel.csv')
    trainer.run()